{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 2 - Árboles de Decisión\n",
    "\n",
    "### Grupo 7:\n",
    "     - S. Volti  C.I. 5.175.914-7\n",
    "     - A. Sierra C.I. 4.647.235-6\n",
    "     - A. Clara C.I. 4.772.294-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetivos de esta tarea son:\n",
    "- Construir clasificadores desde cero utilizando como algoritmos a ID3 y Random Forest.\n",
    "- Construir dichos clasificadores utilizando los mismos algoritmos, pero ahora haciendo uso de las implementaciones de Scikit-Learn.\n",
    "- Evaluar y realizar una comparación entre lo implementando desde cero y lo obtenido con Scikit-Learn.\n",
    "\n",
    "El éxito del aprendizaje se mide a través de la evaluación de los clasificadores sobre un conjunto de evaluación, el cual se obtiene a partir de la partición previa del dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar el dataset, se puede ver que hay una distribución desbalanceada en los ejemplos. Hay muchos más ejemplos con clasificación negativa que positiva (más precisamente, el conjunto de datos QSAR posee 8992 ejemplos, de los cuales 8251 clasifican de forma negativa, y sólo 741 de manera positiva).\n",
    "\n",
    "Una forma de contrarrestar esto es realizando una partición equitativa en cuanto a la proporción negativos/positivos en los conjuntos de entrenamiento y evaluación.\n",
    "\n",
    "Sin embargo, luego de realizar un análisis de las proporciones utilizando simplemente un random.shuffle sobre los datos (y realizando varias ejecuciones con varias semillas), se ve que la proporción se mantiene en términos generales. Por lo que no resulta necesario hacer explícita la estratificación.\n",
    "\n",
    "De cualquier manera cabe destacar que se tuvo el cuidado de que las proporciones fueran adecuadas en todas las evaluaciones presentadas en este informe (todos las particiones realizadas, tanto de entrenamiento como de evaluación, contienen un poco más de 90% de ejemplos que clasifican negativo, y un poco menos de 10% que clasifican positivo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Implementación desde cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la construcción del **árbol de decisión** con ID3 se hace uso de su versión más básica. Para la elección del siguiente atributo, se utiliza la métrica InformationGain, vista en el teórico.\n",
    "\n",
    "A grandes rasgos, a nivel de implementación y para representar a los árboles generados se usan las estructuras dict, de Python, donde cada atributo (valores de ‘0’ a ‘1023’) es representado con una clave, los valores (las ramas) también son claves (“hijas” de cada clave-atributo), y las hojas son representadas mediante valores ‘negative’ y ‘positive’.\n",
    "\n",
    "<img src=\"imagenes/arbol.png\" style=\"width: 320px; display: inline-block;\">\n",
    "\n",
    "Revisando las ganancias calculadas en cada iteración por el algoritmo ID3, se puede notar que a medida que se va bajando hacia las hojas en la construcción de una rama, en determinado momento el cálculo de la ganancia de todos los atributos comienza a tomar el valor 0; hasta que el algoritmo comienza a construir una nueva rama y vuelve a dar valores positivos.\n",
    "Esto sucede en reiteradas ocasiones, y algunas veces con ramas no tan profundas.\n",
    "\n",
    "Cuando la ganancia calculada de todos los atributos vale 0, es indistinto cuál atributo elegir, no hay mejor elección, por lo que el conjunto de atributos deja de tener relevancia para esa iteración en particular.\n",
    "\n",
    "Se realizan algunas pruebas, como detener la construcción de una rama cuando nos el algoritmo está en esta situación, y asignar una hoja con el valor más común del dataset en ese momento. Para probar esto se tiene el parámetro _g_ en la ejecución del programa.\n",
    "\n",
    "Para la construcción del **Random Forest** se usa la idea de implementación vista en el teórico, donde se hace uso de dos hiper-parámetros:\n",
    "\n",
    "- La cantidad de árboles $m$: Dado que la librería skit utiliza por defecto un valor de 100, decidimos generar 100 árboles para iniciar con la experimentación.\n",
    "- La cantidad de atributos $k$: Los valores habituales para k son $\\sqrt{ k }$ y $k/3$ .\n",
    "Para generar cada árbol del Random Forest, se utiliza la implementación ID3 vista más arriba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Implementación de Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la construcción del **árbol de decisión** con Scikit también se utiliza como métrica para seleccionar al siguiente atributo a entropy (la otra opción que ofrece la librería es gini). Los otros parámetros son los determinados por defecto.\n",
    "\n",
    "Para la construcción del **Random Forest** se toman como valores para iniciar las pruebas los mismos que en la parte del ID3 nuestro. Los otros parámetros modificados son los que corresponden a los hiper-parámetros propios de Random Forest ($k$, $m$, $p$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. Conjunto de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para medir la performance los clasificadores se particiona el conjunto original de datos en dos subconjuntos: de entrenamiento y evaluación. \n",
    "\n",
    "Antes de construir los subconjuntos se realiza un shuffle sobre el conjunto de datos, y luego sí se particiona dicho conjunto en dos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Métricas utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originalmente se toma solamente la accuracy como métrica. Sin embargo, como se menciona en la sección de experimentación luego se comienzan a tomar también otras métricas más representativas: precisión, recall, F1 (todas definidas sobre la clase de los positivos). Esto se explica mejor en dicha sección, pero se debe al desbalance del conjunto de datos con respecto a la proporción de positivos/negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Ejecución del programa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución mínima del programa se debe hacer de la siguiente forma:\n",
    "\n",
    "_python3 main.py -s 7 -t 0.8 -p c_\n",
    "\n",
    "donde:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th style=\"text-align: left\"><b>Parámetro</b></th>\n",
    "    <th style=\"text-align: left\"><b>Descripción</b></th>\n",
    "    <th style=\"text-align: left; width: 80px\"><b>Por defecto</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>s</b></td>\n",
    "    <td style=\"text-align: left\">Semilla utilizada por los paquetes random y numpy (para Scikit).</td>\n",
    "    <td>-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>t</b></td>\n",
    "    <td style=\"text-align: left\">Fracción de los ejemplos usados para el entrenamiento (0.8 = 80% de entrenamiento, 20% de evaluacion).</td>\n",
    "    <td>-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>p</b></td>\n",
    "    <td style=\"text-align: left\">Parte de la letra a ejecutar (a ejecuta la parte a, etc).</td>\n",
    "    <td>-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>d</td>\n",
    "    <td style=\"text-align: left\">Nivel de debug para los prints (0 no imprime nada, 1 solo información, 2 datos para debugging).</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>m</td>\n",
    "    <td style=\"text-align: left\">Valor de m (cantidad de árboles) para construir el random forest.</td>\n",
    "    <td>100</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>q</td>\n",
    "    <td style=\"text-align: left\">En el contexto de random forest, indica con un 1 si se usa la raíz cuadrada de k para la cantidad de atributos, o si se usa k/3 (con un 0).</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>k</td>\n",
    "    <td style=\"text-align: left\">Parámetro k utilizado para cross validation.</td>\n",
    "    <td>5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>r</td>\n",
    "    <td style=\"text-align: left\">Indica si se deben imprimir los análisis intermedios sobre las estructuras generadas por las implementaciones.</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>b</td>\n",
    "    <td style=\"text-align: left\">Indica si se trabajará con el dataset original (8992 ejemplos) o se utilizará un dataset de prueba balanceado (compuesto de los 741 ejemplos que califican positivo, y 741 ejemplos que clasifican negativo tomados al azar).</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>g</td>\n",
    "    <td style=\"text-align: left\">Indica si se detendrá la recursión de ID3 cuando la ganancia máxima de los atributos es cero.</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>c</td>\n",
    "    <td style=\"text-align: left\">Indica con c > 0 la cantidad de iteraciones con la que se realizará validación cruzada.</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "**Observación:** Los parámetros _s_, _t_ y _p_ son obligatorios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Implementaciones de ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Primera implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primera instancia, resulta interesante destacar que al terminar la “primera iteración” de implementación de ID3 y con una evaluación superficial de los resultados (donde simplemente se evalúan clasificaciones correctas vs incorrectas) se obtiene un porcentaje de aciertos del 92%, muy cercano al de Scikit.\n",
    "\n",
    "Esto claramente genera dudas, por lo que se comienza a realizar un análisis con mayor profundidad. Se empiezan a evaluar los porcentajes de acierto por clase, y se puede ver que la mayoría de las clasificaciones erróneas (sino todas) se dan en el caso de los positivos (por ejemplo, 2 clasificaciones correctas en 172). Es decir, el árbol generado con la primera implementación de ID3, clasifica como negativo a la mayoría de los que son positivos. El resto de las clasificaciones es correcta porque los ejemplos de evaluación tienen clasificación negativa.\n",
    "\n",
    "Para confirmar lo dicho anteriormente se realiza una ejecución, y se realiza una comparación de las clasificaciones obtenidas por Scikit contra esta primera implementación, con una distribución 80/20 en los conjuntos de entrenamiento/evaluación.\n",
    "Dentro de dicho conjunto, hay 1654 ejemplos negativos, y 145 positivos.\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Clasif. +</b></th>\n",
    "    <th><b>Clasif. -</b></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td>13</td>\n",
    "    <td>1786</td>\n",
    "    <td><b>91.43%</b></td>\n",
    "    <td style=\"color: red;\">15.38%</td>\n",
    "    <td style=\"color: red;\">1.37%</td>\n",
    "    <td style=\"color: red;\">2.53%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td>159</td>\n",
    "    <td>1640</td>\n",
    "    <td>90.99%</td>\n",
    "    <td><b>44.65%</b></td>\n",
    "    <td><b>48.96%</b></td>\n",
    "    <td><b>46.71%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla 1 - Comparación entre los resultados de la implementación de Scikit y nuestra <b>primera</b> implementación de ID3</caption>\n",
    "</table>\n",
    "\n",
    "Lo interesante a destacar es cómo a pesar de tener errores de implementación, la precisión vista de forma cruda puede seguir siendo alta. Al incluir la precisión y el recall, se puede observar la baja performance que tiene esta primera implementación.\n",
    "\n",
    "Lo analizado anteriormente claramente induce a pensar que hay un error de implementación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Implementación final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de realizar algunos ajustes en el algoritmo ID3, se comienzan a lograr mejores resultados en términos generales de las métricas.\n",
    "\n",
    "A continuación se presenta una pieza del código que permite realizar la ejecución de la implementación final de nuestro ID3 y la de Scikit. Los parámetros a asignar se encuentran al comienzo del código, luego de los imports. Si se quieren probar los otros parámetros, se debe hacer una ejecución desde el main del proyecto como se indica en la sección de ejecución del programa.\n",
    "\n",
    "Se imprimen los resultados de ambas implementaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo el csv...\n",
      "Construyendo el árbol con nuestro ID3...\n",
      "Construyendo el árbol con Scikit...\n",
      "Clasificando ejemplos de evaluación con nuestro ID3...\n",
      "Clasificando ejemplos de evaluación con Scikit...\n",
      "\n",
      "Resultados con nuestro ID3:\n",
      "Accuracy: 91.50%\n",
      "Precisión: 47.50%\n",
      "Recall: 52.41%\n",
      "\n",
      "Resultados con Scikit:\n",
      "Accuracy: 90.99%\n",
      "Precisión: 44.65%\n",
      "Recall: 48.97%\n"
     ]
    }
   ],
   "source": [
    "import id3\n",
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import scikit\n",
    "import sys\n",
    "import utils\n",
    "\n",
    "########## Parámetros ##########\n",
    "\n",
    "PROPORTION = 0.8 # Indica la proporción a usar en la partición del dataset para entrenamiento/evaluación\n",
    "SEED = 3 # Indica la semilla a utilizar para los paquetes random\n",
    "\n",
    "################################\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(message)s')\n",
    "sys.setrecursionlimit(3000)\n",
    "\n",
    "# Definir las semillas a utilizar por los paquetes con operaciones aleatorias\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"Leyendo el csv...\")\n",
    "data = utils.load_data('qsar_oral_toxicity.csv')\n",
    "\n",
    "# Definir los atributos iniciales para el algoritmo ID3\n",
    "initial_attributes = [str(i) for i in range(1024)]\n",
    "\n",
    "# Separar los conjuntos en entrenamiento | validación\n",
    "training_set, test_set = utils.partition_sets(data, PROPORTION)\n",
    "\n",
    "# Separar los conjuntos en atributos | clase\n",
    "training_examples, training_classes = utils.get_classes(training_set)\n",
    "test_examples, test_classes = utils.get_classes(test_set)\n",
    "\n",
    "# Construir los árboles con ID3\n",
    "print(\"Construyendo el árbol con nuestro ID3...\")\n",
    "classifier_id3 = id3.id3(training_set, initial_attributes, 0)\n",
    "print(\"Construyendo el árbol con Scikit...\")\n",
    "classifier_id3_sk = scikit.scikit_id3(training_examples, training_classes)\n",
    "\n",
    "# Evaluar el clasificador con el conjunto de evaluación\n",
    "print(\"Clasificando ejemplos de evaluación con nuestro ID3...\")\n",
    "classification_id3 = id3.classify_examples(classifier_id3, test_examples, test_classes)\n",
    "print(\"Clasificando ejemplos de evaluación con Scikit...\")\n",
    "classification_id3_sk = scikit.classify_examples(classifier_id3_sk, test_examples, test_classes)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Resultados con nuestro ID3:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(classification_id3['accuracy'] * 100))\n",
    "print(\"Precisión: {:.2f}%\".format(classification_id3['precision'] * 100))\n",
    "print(\"Recall: {:.2f}%\".format(classification_id3['recall'] * 100))\n",
    "print(\"\")\n",
    "print(\"Resultados con Scikit:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(classification_id3_sk['accuracy'] * 100))\n",
    "print(\"Precisión: {:.2f}%\".format(classification_id3_sk['precision'] * 100))\n",
    "print(\"Recall: {:.2f}%\".format(classification_id3_sk['recall'] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulta interesante destacar que detener la construcción de una rama cuando la ganancia máxima de los atributos toma valor cero (parámetro _g_), no alteró los resultados finales obtenidos (accuracy, precisión, recall, F1); pero sí disminuyó notoriamente la cantidad de ramificaciones y hojas del árbol clasificador resultante, lo que brinda una mejor performance para la construcción del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.1. Evaluación simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primera instancia se realiza una evaluación simple con las siguientes métricas: accuracy, precision, recall, y F1. Luego se realiza una evaluación con validación cruzada.\n",
    "\n",
    "**Distribución 80/20**\n",
    "\n",
    "Ejecución 1:\n",
    "- semilla = 5\n",
    "- 137 ejemplos positivos\n",
    "- 1662 ejemplos negativos\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td>91.33%</td>\n",
    "    <td>43.45%</td>\n",
    "    <td><b>45.99%</b></td>\n",
    "    <td>44.68%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td><b>91.61%</b></td>\n",
    "    <td><b>44.93%</b></td>\n",
    "    <td>45.26%</td>\n",
    "    <td><b>45.09%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla 2 - ID3 - Nuestra vs Scikit. s = 5, d = 80/20</caption>\n",
    "</table>\n",
    "\n",
    "\n",
    "Ejecución 2:\n",
    "- semilla = 10\n",
    "- 147 ejemplos positivos\n",
    "- 1652 ejemplos negativos\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td><b>92.05%</b></td>\n",
    "    <td><b>51.37%</b></td>\n",
    "    <td><b>51.02%</b></td>\n",
    "    <td><b>51.19%</b></td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td>91.11%</td>\n",
    "    <td>45.64%</td>\n",
    "    <td>46.26%</td>\n",
    "    <td>45.95%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla 3 - ID3 - Nuestra vs Scikit. s = 10, d = 80/20</caption>\n",
    "</table>\n",
    "\n",
    "\n",
    "Ejecución 3:\n",
    "- semilla = 324\n",
    "- 145 ejemplos positivos\n",
    "- 1654 ejemplos negativos\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td>91.27%</td>\n",
    "    <td>45.52%</td>\n",
    "    <td>42.07%</td>\n",
    "    <td>43.73%</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td><b>91.88%</b></td>\n",
    "    <td><b>49.64%</b></td>\n",
    "    <td><b>46.90%</b></td>\n",
    "    <td><b>48.23%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla 4 - ID3 - Nuestra vs Scikit. s = 324, d = 80/20</caption>\n",
    "</table>\n",
    "\n",
    "**Distribución 90/10**\n",
    "\n",
    "Ejecución 1:\n",
    "- semilla = 5\n",
    "- 74 ejemplos de validación positivos\n",
    "- 826 ejemplos de validación negativos\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td><b>91.22%</b></td>\n",
    "    <td><b>46.15%</b></td>\n",
    "    <td><b>40.54%</b></td>\n",
    "    <td><b>43.17%</b></td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td>91.00%</td>\n",
    "    <td>44.78%</td>\n",
    "    <td><b>40.54%</b></td>\n",
    "    <td>42.55%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla 5 - ID3 - Nuestra vs Scikit. s = 5, d = 90/10</caption>\n",
    "</table>\n",
    "\n",
    "Ejecución 2:\n",
    "- semilla = 10\n",
    "- 78 ejemplos de validación positivos\n",
    "- 822 ejemplos de validación negativos\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td><b>91.33%</b></td>\n",
    "    <td><b>50.00%</b></td>\n",
    "    <td><b>56.41%</b></td>\n",
    "    <td><b>53.01%</b></td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td>91.00%</td>\n",
    "    <td>48.28%</td>\n",
    "    <td>53.85%</td>\n",
    "    <td>50.91%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla 6 - ID3 - Nuestra vs Scikit. s = 10, d = 90/10</caption>\n",
    "</table>\n",
    "\n",
    "Ejecución 3:\n",
    "- semilla = 324\n",
    "- 69 ejemplos de validación positivos\n",
    "- 831 ejemplos de validación negativos\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td>91.33%</td>\n",
    "    <td>43.48%</td>\n",
    "    <td>43.48%</td>\n",
    "    <td>43.48%</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td><b>92.22%</b></td>\n",
    "    <td><b>49.28%</b></td>\n",
    "    <td><b>49.28%</b></td>\n",
    "    <td><b>49.28%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla 7 - ID3 - Nuestra vs Scikit. s = 324, d = 90/10</caption>\n",
    "</table>\n",
    "\n",
    "Como conclusiones de los resultados obtenidos en esta sección:\n",
    "- En comparación con la primera implementación, se logra un acercamiento importante a lo obtenido por Scikit, y con algunas semillas incluso se logra superarlo en todas las métricas.\n",
    "- En ambas distribuciones (80/20, 90/10), se logran resultados similares en ambos algoritmos para todas las semillas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.2. Evaluación con conjunto de datos equilibrado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las pruebas que realizamos para analizar cómo funcionaba nuestro algoritmo, fue la de trabajar sobre un conjunto de datos balanceado.\n",
    "Como mencionamos anteriormente, el conjunto de datos original consta de solamente 741 ejemplos que califican de manera positiva, habiendo un total de 8992 ejemplos).\n",
    "\n",
    "Para trabajar con un conjunto de datos equilibrado (parámetro -b) depuramos el mismo, trabajando solamente con los 741 ejemplos que califican de forma positiva, y con 741 ejemplos que califican de manera negativa, estos últimos escogidos al azar del conjunto de datos).\n",
    "Por lo tanto nuestro Conjunto de Datos Equilibrado consta de 1482 ejemplos, 50% negativos y 50% positivos.\n",
    "Utilizando las mismas métricas que en la sección anterior, y estudiando por ejemplo la distribución 80/20, se obtienen los siguientes resultados:\n",
    "\n",
    "**Distribución 80/20**\n",
    "\n",
    "Ejecución 1:\n",
    "- semilla = 5\n",
    "- 134 ejemplos positivos\n",
    "- 163 ejemplos negativos\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td>74.41%</td>\n",
    "    <td>69.59%</td>\n",
    "    <td>76.87%</td>\n",
    "    <td>73.05%</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td><b>75.42%</b></td>\n",
    "    <td><b>70.75%</b></td>\n",
    "    <td><b>77.61%</b></td>\n",
    "    <td><b>74.02%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla 8 - ID3 - Nuestra vs Scikit. s = 5, d = 80/20</caption>\n",
    "</table>\n",
    "\n",
    "Ejecución 2:\n",
    "- semilla = 10\n",
    "- 159 ejemplos positivos\n",
    "- 138 ejemplos negativos\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td>77.44%</td>\n",
    "    <td><b>81.51%</b></td>\n",
    "    <td>74.84%</td>\n",
    "    <td>78.03%</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td><b>78.54%</b></td>\n",
    "    <td>79.50%</td>\n",
    "    <td><b>80.50%</b></td>\n",
    "    <td><b>80.00%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla 9 - ID3 - Nuestra vs Scikit. s = 10, d = 80/20</caption>\n",
    "</table>\n",
    "\n",
    "Ejecución 3\n",
    "- semilla = 324\n",
    "- 147 ejemplos positivos\n",
    "- 150 ejemplos negativos\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td><b>78.11%</b></td>\n",
    "    <td>76.62%</td>\n",
    "    <td><b>80.27%</b></td>\n",
    "    <td><b>78.41%</b></td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td><b>78.11%</b></td>\n",
    "    <td><b>77.33%</b></td>\n",
    "    <td>78.91%</td>\n",
    "    <td>78.11%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla 10 - ID3 - Nuestra vs Scikit. s = 324, d = 80/20</caption>\n",
    "</table>\n",
    "\n",
    "Como conclusiones de los resultados obtenidos en esta sección:\n",
    "- En estas ejecuciones sobre un conjunto de datos equilibrado, se puede notar que se pierde más de un 10% de accuracy, pero se gana bastante en el resto de las métricas.\n",
    "- De cualquier manera, comparando nuestro algoritmo contra el de Scikit, se siguen obteniendo evaluaciones similares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.3. Evaluación utilizando “k” Folds Cross Validation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otras de las pruebas que realizamos para analizar cómo funcionaba nuestro algoritmo, fue la de realizar validación cruzada de “k” iteraciones sobre nuestro conjunto de datos.\n",
    "\n",
    "La validación cruzada supone una mejora del método de evaluación simple detallado en las secciones anteriores.\n",
    "La misma consiste en dividir los datos en “k” subconjuntos. Uno de los subconjuntos se utiliza como datos de prueba y el resto (k-1) se utilizan como datos de entrenamiento.\n",
    "\n",
    "El proceso de validación cruzada es repetido durante “k” iteraciones, con cada uno de los posibles subconjuntos de datos de prueba.\n",
    "Entonces, para cada iteración, obtenemos un conjunto de entrenamiento compuesto de (k-1) subconjuntos, y un conjunto de prueba compuesto solamente de un subconjunto de datos.\n",
    "Por último, se calcula el promedio de los resultados de cada iteración para obtener un único resultado, lo que supone un resultado más representativo y preciso.\n",
    "\n",
    "En particular optamos por realizar estas pruebas siempre con una distribución de datos (entrenamiento/prueba) de 90/10 %, por lo tanto implementamos validación cruzada con 10 iteraciones. (Igualmente la cantidad de iteraciones depende del parámetro “c” que recibe nuestro algoritmo).\n",
    "Por tanto, en cada iteración, tendremos un conjunto de entrenamiento compuesto de 9 subconjuntos de datos, y un conjunto de prueba compuesto del subconjunto restante.\n",
    "\n",
    "A continuación, detallamos los resultados y comparaciones obtenidas. Para realizar las comparaciones detalladas, se utilizó validación cruzada de 10 iteraciones tanto para nuestra implementación de ID3 como para la implementación de scikit-learn:\n",
    "\n",
    "**Distribución 90/10, promedios de resultados obtenidos:**\n",
    "\n",
    "Ejecución 1:\n",
    "- semilla = 5\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td>91.30%</td>\n",
    "    <td>46.93%</td>\n",
    "    <td>48.00%</td>\n",
    "    <td>47.22%</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td><b>91.59%</b></td>\n",
    "    <td><b>48.83%</b></td>\n",
    "    <td><b>49.62%</b></td>\n",
    "    <td><b>49.01%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla 11 - ID3 - Nuestra vs Scikit. s = 5, d = 90/10</caption>\n",
    "</table>\n",
    "\n",
    "Ejecución 2:\n",
    "- semilla = 10\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td><b>91.29%</b></td>\n",
    "    <td>47.09%</td>\n",
    "    <td>50.24%</td>\n",
    "    <td>48.32%</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td>91.13%</td>\n",
    "    <td><b>47.65%</b></td>\n",
    "    <td><b>50.67%</b></td>\n",
    "    <td><b>49.00%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla 12 - ID3 - Nuestra vs Scikit. s = 10, d = 90/10</caption>\n",
    "</table>\n",
    "\n",
    "Ejecución 3\n",
    "- semilla = 324\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td><b>91.23%</b></td>\n",
    "    <td><b>47.36%</b></td>\n",
    "    <td><b>49.97%</b></td>\n",
    "    <td><b>48.41%</b></td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td>90.79%</td>\n",
    "    <td>44.76%</td>\n",
    "    <td>48.70%</td>\n",
    "    <td>46.46%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla 13 - ID3 - Nuestra vs Scikit. s = 324, d = 90/10</caption>\n",
    "</table>\n",
    "\n",
    "Como conclusiones de estas pruebas podemos aportar que si bien se mantuvieron los resultados obtenidos para Accuracy y Precisión, logramos obtener resultados más representativos para Recall y F1 (en comparación con las previas implementaciones sin utilizar validación cruzada); y equilibramos todos los porcentajes, sin importar la semilla con la que trabajamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Implementaciones de Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la construcción de los Random Forests nuestros, se hace uso de la implementación previa con ID3.\n",
    "\n",
    "A continuación se presenta una pieza del código que permite realizar la ejecución de la implementación final de nuestro Random Forest y la de Scikit. Se imprimen los resultados de ambas implementaciones.\n",
    "\n",
    "Los parámetros de Random Forest tienen la siguiente notación:\n",
    "- cant_atributos: Cantidad de atributos del dataset original.\n",
    "- m: Cantidad de árboles que componen al Random Forest.\n",
    "- k: Cantidad de elementos del dataset para entrenar cada árbol.\n",
    "- p: Cantidad de atributos tomados en cuenta para cada árbol.\n",
    "\n",
    "**Observación:** Se puede utilizar un valor pequeño para m para realizar las pruebas de forma rápida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo el csv...\n",
      "Construyendo Random Forest nuestro...\n",
      "Construyendo Random Forest con Scikit...\n",
      "Clasificando ejemplos de evaluación con Random Forest Nuestro...\n",
      "Clasificando ejemplos de evaluación con Random Forest de Scikit...\n",
      "\n",
      "Resultados Random Forest nuestro:\n",
      "Accuracy: 92.66%\n",
      "Precisión: 60.32%\n",
      "Recall: 26.21%\n",
      "\n",
      "Resultados Random Forest de Scikit:\n",
      "Accuracy: 93.39%\n",
      "Precisión: 69.12%\n",
      "Recall: 32.41%\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import random_forest\n",
    "import scikit\n",
    "import sys\n",
    "import utils\n",
    "\n",
    "########## Parámetros ##########\n",
    "\n",
    "PROPORTION = 0.8 # Indica la proporción a usar en la partición del dataset para entrenamiento/evaluación\n",
    "SEED = 3 # Indica la semilla a utilizar para los paquetes random\n",
    "m = 2 # Valor de m (cantidad de árboles) para realizar el random forest. Por defecto es 100\n",
    "use_sqrt = 0 # Indica con un 1 si se usa la raíz cuadrada de k para la cantidad de atributos, o si se usa k/3 (con un 0)\n",
    "\n",
    "################################\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING, format='%(message)s')\n",
    "sys.setrecursionlimit(3000)\n",
    "\n",
    "# Definir las semillas a utilizar por los paquetes con operaciones aleatorias\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"Leyendo el csv...\")\n",
    "data = utils.load_data('qsar_oral_toxicity.csv')\n",
    "\n",
    "# Separar los conjuntos en entrenamiento | validación\n",
    "training_set, test_set = utils.partition_sets(data, PROPORTION)\n",
    "\n",
    "# Separar los conjuntos en atributos | clase\n",
    "training_examples, training_classes = utils.get_classes(training_set)\n",
    "test_examples, test_classes = utils.get_classes(test_set)\n",
    "\n",
    "# Construir los árboles con ID3\n",
    "k_rf = len(training_set) # k = |D|\n",
    "\n",
    "print(\"Construyendo Random Forest nuestro...\")\n",
    "classifier_rf = random_forest.RandomForest(k_rf, m, 1024, training_set, 0, use_sqrt)\n",
    "print(\"Construyendo Random Forest con Scikit...\")\n",
    "classifier_rf_sk = scikit.scikit_rf(training_examples, training_classes, m, use_sqrt)\n",
    "\n",
    "# Evaluar el clasificador con el conjunto de evaluación\n",
    "print(\"Clasificando ejemplos de evaluación con Random Forest Nuestro...\")\n",
    "classification_rf = classifier_rf.Evaluation_testset(test_examples,test_classes)\n",
    "print(\"Clasificando ejemplos de evaluación con Random Forest de Scikit...\")\n",
    "classification_rf_sk = scikit.classify_examples(classifier_rf_sk, test_examples, test_classes)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Resultados Random Forest nuestro:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(classification_rf['accuracy'] * 100))\n",
    "print(\"Precisión: {:.2f}%\".format(classification_rf['precision'] * 100))\n",
    "print(\"Recall: {:.2f}%\".format(classification_rf['recall'] * 100))\n",
    "print(\"\")\n",
    "print(\"Resultados Random Forest de Scikit:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(classification_rf_sk['accuracy'] * 100))\n",
    "print(\"Precisión: {:.2f}%\".format(classification_rf_sk['precision'] * 100))\n",
    "print(\"Recall: {:.2f}%\".format(classification_rf_sk['recall'] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Implementación final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.1. Evaluación simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primera instancia se realiza una evaluación simple con las siguientes métricas: accuracy, precision, recall, y F1.\n",
    "\n",
    "En todas las pruebas presentadas a continuación se toma un $k = |Dataset| = 1024$.\n",
    "\n",
    "Para comenzar las pruebas se toma un p = sqrt(cant_atributos). En nuestro caso particular, $cant\\_atributos = 1024$, por lo que $p = 32$.\n",
    "\n",
    "**Distribución 80/20**\n",
    "\n",
    "Ejecución 1:\n",
    "- semilla = 5\n",
    "- m = 100\n",
    "- p = 32\n",
    "- 137 ejemplos de validación positivos\n",
    "- 1662 ejemplos de validación negativos\n",
    "\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td>92.83%</td>\n",
    "    <td><b>75.00%</b></td>\n",
    "    <td style=\"color: red;\">8.76%</td>\n",
    "    <td style=\"color: red;\">15.69%</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td><b>94.16%</b></td>\n",
    "    <td>69.05%</td>\n",
    "    <td><b>42.34%</b></td>\n",
    "    <td><b>52.49%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla 14 - RF - Nuestra vs Scikit. s = 5, d = 80/20, m = 100, p = 32</caption>\n",
    "</table>\n",
    "\n",
    "Ejecución 2:\n",
    "- semilla = 10\n",
    "- m = 100\n",
    "- p = 32\n",
    "- 147 ejemplos de validación positivos\n",
    "- 1652 ejemplos de validación negativos\n",
    "\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td>92.44%</td>\n",
    "    <td><b>92.31%</b></td>\n",
    "    <td style=\"color: red;\">8.16%</td>\n",
    "    <td style=\"color: red;\">15.00%</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td><b>94.2%</b></td>\n",
    "    <td>78.67%</td>\n",
    "    <td><b>40.14%</b></td>\n",
    "    <td><b>53.15%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla 15 - RF - Nuestra vs Scikit. s = 10, d = 80/20, m = 100, p = 32</caption>\n",
    "</table>\n",
    "\n",
    "\n",
    "**Distribución 90/10**\n",
    "\n",
    "Ejecución 1:\n",
    "- semilla = 5\n",
    "- m = 100\n",
    "- p = 341\n",
    "- 74 ejemplos de validación positivos\n",
    "- 826 ejemplos de validación negativos\n",
    "\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td><b>94.61%</b></td>\n",
    "    <td><b>72.22%</b></td>\n",
    "    <td>47.45%</td>\n",
    "    <td><b>57.27%</b></td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td>94.39%</td>\n",
    "    <td>68.75%</td>\n",
    "    <td><b>48.18%</b></td>\n",
    "    <td>56.65%</td>\n",
    "  </tr>\n",
    "    <caption>Tabla 16 - RF - Nuestra vs Scikit. s = 5, d = 90/10, m = 100, p = 341</caption>\n",
    "</table>\n",
    "\n",
    "Ejecución 2:\n",
    "- semilla = 10\n",
    "- m = 100\n",
    "- p = 341\n",
    "- 74 ejemplos de validación positivos\n",
    "- 826 ejemplos de validación negativos\n",
    "\n",
    "\n",
    "<table style=\"display: inline-block; margin-left: 48px;\">\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><b>Accuracy</b></th>\n",
    "    <th><b>Precisión</b></th>\n",
    "    <th><b>Recall</b></th>\n",
    "    <th><b>F1</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Nuestra</b></td>\n",
    "    <td>93.56%</td>\n",
    "    <td>71.74%</td>\n",
    "    <td>42.31%</td>\n",
    "    <td>53.23%</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td><b>Scikit</b></td>\n",
    "    <td><b>94.33%</b></td>\n",
    "    <td><b>75.47%</b></td>\n",
    "    <td><b>51.28%</b></td>\n",
    "    <td><b>61.07%</b></td>\n",
    "  </tr>\n",
    "    <caption>Tabla 17 - RF - Nuestra vs Scikit. s = 10, d = 90/10, m = 100, p = 341</caption>\n",
    "</table>\n",
    "\n",
    "Como conclusiones de los resultados obtenidos en esta sección:\n",
    "- Se obtienen malos resultados en términos de recall cuadno p es chico (p = 32). Se obtiene una gran mejora al aumentarlo y usar p = 341."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.2. Pruebas variando $m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se realiza una comparación entre las métricas ambas implementaciones de Random Forest a medida que se varía $m$.\n",
    "\n",
    "Algunas observaciones a tener en cuenta:\n",
    "- Se prueban los siguientes valores de $m$: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512].\n",
    "- La distribución de los conjuntos es 80% entrenamiento, 20% validación.\n",
    "- La escala sobre el eje de las x se presenta de forma logarítmica.\n",
    "- Para las pruebas se usa el valor de $p$ que dio mejores resultados en la sección anterior, es decir, $p = cant\\_atributos\\space/\\space3 = 341$.\n",
    "- Para cada valor de $m$ se entrena sobre el mismo conjunto de entrenamiento y se evalúa sobre el mismo conjunto de validación.\n",
    "\n",
    "**Observación:** Todos los gráficos corresponden a comparaciones sin utilizar validación cruzada.\n",
    "\n",
    "<div style=\"width: 45%; display: inline-block;\">\n",
    "  <img src=\"imagenes/graficas/s7_t08_mvar_10_accuracy.png\">\n",
    "</div>\n",
    "\n",
    "<div style=\"width: 45%; display: inline-block;\">\n",
    "  <img src=\"imagenes/graficas/s7_t08_mvar_10_precision.png\">\n",
    "</div>\n",
    "\n",
    "<div style=\"width: 45%; display: inline-block;\">\n",
    "  <img src=\"imagenes/graficas/s7_t08_mvar_10_recall.png\">\n",
    "</div>\n",
    "\n",
    "<div style=\"width: 45%; display: inline-block;\">\n",
    "  <img src=\"imagenes/graficas/s7_t08_mvar_10_f1.png\">\n",
    "</div>\n",
    "\n",
    "Como conclusiones de los resultados obtenidos en esta sección:\n",
    "- La accuracy se mantiene cercana al 90% para ambas implementaciones a partir de m=2.\n",
    "- En términos generales se puede decir que la implementación con scikit tiene una mejor performance (sobre todo si se observa la variación de f1).\n",
    "- La performance en términos de las métricas evaluadas en m=32 mejora para nuestra implementación, pero empeora notoriamente para m=128.\n",
    "- La tendencia en términos generales de la implementación de scikit es de mejorar a medida que aumenta m hasta m=128, luego comienza a bajar. Para nuestra implementación hay una mayor variabilidad, alcanzando los mejores valores de f1 para m=256.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas conclusiones generales y posibles mejoras en las evaluaciones:\n",
    "- En las experimentaciones con el algoritmo ID3 se obtienen valores de accuracy altos. Esto nos llevó a introducir las métricas de recall y precisión, pues en el dataset hay una gran cantidad de ejemplos negativos y si obtenemos por ejemplo un clasificador que a cualquier instancia la clasifica como negativa esto daría un valor alto de accuracy, lo cual no es garantía de que sea un buen clasificador. Las métricas de recall y precisión nos dieron una idea más real pues nos dicen qué tan bueno es nuestro clasificador al decir que un ejemplo es positivo y cuántos de los verdaderos ejemplos positivos clasificamos como positivos. Luego utilizamos la métrica F1 dando igual peso a las métricas de recall y precisión pues es igual de importante ser preciso a la hora de clasificar una instancia como positiva así como clasificar bien la mayor cantidad de ejemplos positivos.\n",
    "- Como conclusión sobre las pruebas realizadas con el algoritmo de validación cruzada podemos decir que si bien se mantuvieron los resultados obtenidos para Accuracy y Precisión, logramos obtener resultados más representativos para Recall y F1 (en comparación con las previas implementaciones). Validación cruzada genera resultados más reales en el sentido que disminuye la varianza de los resultados gracias al cálculo del promedio.\n",
    "- Con respecto a los hiperparametros en el algoritmo Random Forest, cuando la cantidad de árboles construidos es aproximadamente mayor a 128 no se ve una gran mejora en las métricas elegidas, pero la cantidad de atributos sí genera mejores resultados cuanto más grande es. Creemos que esto se debe a que el algoritmo de ID3 tiene más posibilidades en cada paso para elegir el atributo que genera mejor ganancia, pudiendo así separar el conjunto de ejemplos de entrenamiento de una mejor manera. Dado que Random Forest genera un gran costo en términos de tiempo no probamos con cantidades de atributos mayores, pero creemos que ocurriría algo similar a lo que ocurre con la cantidad de árboles construidos. Luego de cierto número (no mayor a la cantidad total de atributos posibles) no se generarían aumentos significativos en las métricas.\n",
    "- Como mejora creemos que no es del todo correcto buscar los mejores hiperparametros en base al conjunto de evaluación, como se vio en el teórico esto puede dar lugar a sobre ajustes. Esto se puede paliar con dos estrategias. Una es separando un tercer conjunto (de validación) del dataset. La otra es usar validación cruzada. Inicialmente quisimos utilizar el algoritmo implementado de validación cruzada para esto pero fue muy costoso en términos de tiempo.\n",
    "- En particular, en las pruebas variando m se utilizó solamente una separación hold-out. Es decir, a partir de estas evaluaciones se puede tener una idea de cuáles son los valores de m óptimos para cada implementación, pero si se usara validación cruzada dichos valores serían más confiables. Además, no se dividió el dataset en tres. Por lo que no se tiene un conjunto de evaluación, y por lo tanto no es del todo correcto realizar un análisis comparativo en cuanto a la performance de nuestra implementación y la de scikit. Para realizar tales conclusiones sería necesario justamente, una comparación de las performances sobre un tercer conjunto.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
